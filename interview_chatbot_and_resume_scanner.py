# -*- coding: utf-8 -*-
"""Interview Chatbot and Resume Scanner.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M2PiSspgwwYgizm4d8TQ9r98ciq1NUam
"""

!pip install python-docx -q
!pip install transformers gradio pdfplumber sentencepiece -q

#  Step 2: Import libraries
import gradio as gr
import pdfplumber
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import torch

#  Step 3: Load models
tokenizer_qg = AutoTokenizer.from_pretrained("google/flan-t5-base")
model_qg = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
sentiment_pipeline = pipeline("sentiment-analysis")

#  Step 4: Resume Text Extraction
from docx import Document

def extract_text_from_file(file):
    if file.name.endswith(".pdf"):
        import pdfplumber
        with pdfplumber.open(file.name) as pdf:
            full_text = ""
            for page in pdf.pages:
                full_text += page.extract_text() + "\n"
        return full_text.strip()

    elif file.name.endswith(".docx"):
        doc = Document(file.name)
        return "\n".join([para.text for para in doc.paragraphs])

    else:
        return "Unsupported file format. Please upload PDF or DOCX."

#  Step 5: Generate 5 questions using FLAN-T5
def generate_questions(resume_text, num=5):
    prompt = (
        f"Based on this resume:\n\n{resume_text[:700]}\n\n"
        f"Generate {num} diverse and unique interview questions, including technical, experience-based, and behavioral aspects. "
        "Avoid repeating similar questions. Format each question as a separate line."

    )
    inputs = tokenizer_qg(prompt, return_tensors="pt")
    outputs = model_qg.generate(**inputs, max_new_tokens=256)
    result = tokenizer_qg.decode(outputs[0], skip_special_tokens=True)

    # Extract questions containing '?'
    questions = list({q.strip("-â€¢1234567890. ").strip() for q in result.split("\n") if "?" in q})

    # Fill or truncate to exactly num questions
    fallback = [
        "What are your key technical strengths?",
        "Can you walk me through your most impactful project?",
        "How do you handle working under pressure?",
        "What are your long-term career goals?",
        "Describe a time you worked in a team."
    ]
    while len(questions) < num:
        questions.append(fallback[len(questions)])
    return questions[:num]

# Step 6: Interview State
state = {
    "resume_text": "",
    "questions": [],
    "index": 0,
    "score": 0,
    "chat": []
}

#  Step 7: Handle resume upload
def upload_resume(file):
    text = extract_text_from_file(file)
    state["resume_text"] = text
    state["questions"] = generate_questions(text)
    state["index"] = 0
    state["score"] = 0
    state["chat"] = []

    return "Resume uploaded. Click 'Start Interview'."

# Step 8: Start Interview
def start_interview():
    if not state["questions"]:
        return " Upload resume first."
    q = state["questions"][state["index"]]
    state["chat"].append((" Interviewer", q))
    return q

#  Step 9: Answer Handling
def handle_answer(user_answer):
    idx = state["index"]
    if idx >= len(state["questions"]):
        return " Interview already completed."

    # Analyze answer
    feedback = sentiment_pipeline(user_answer)[0]
    label = feedback["label"]
    confidence = feedback["score"]

    if label == "POSITIVE":
        state["score"] += 1

    # Store chat
    state["chat"].append((" You", user_answer))
    state["chat"].append((" Interviewer", f" Feedback: Your answer sounds **{label.lower()}** (Confidence: {confidence:.2f})"))

    # Next question or end
    state["index"] += 1
    if state["index"] < len(state["questions"]):
        next_q = state["questions"][state["index"]]
        state["chat"].append((" Interviewer", next_q))
        return next_q
    else:
        final = f" Interview completed. Score: {state['score']} / {len(state['questions'])}."
        if state["score"] >= 4:
            final += "\n Great job! Confident and clear answers."
        elif state["score"] >= 2:
            final += "\n Decent effort. Try adding more details and structure."
        else:
            final += "\n Needs improvement. Try to communicate more clearly."
        state["chat"].append((" Interviewer", final))
        return final

#  Step 10: Gradio UI
with gr.Blocks() as demo:
    gr.Markdown(" Resume Based QNA Chatbot")

    with gr.Row():
        file_upload = gr.File(label=" Upload Resume (PDF or DOCX)", file_types=[".pdf", ".docx"])
        upload_btn = gr.Button("Analyze Resume")
        output_msg = gr.Textbox(label="Status", lines=2)

    start_btn = gr.Button(" Start Interview")
    question_box = gr.Textbox(label="Interview Question", interactive=False)
    answer_box = gr.Textbox(label="Your Answer")
    submit_btn = gr.Button("Submit Answer")
    chatbox = gr.Chatbot(label="Chat History")

    upload_btn.click(upload_resume, inputs=file_upload, outputs=output_msg)
    start_btn.click(start_interview, outputs=question_box)
    submit_btn.click(handle_answer, inputs=answer_box, outputs=question_box)
    submit_btn.click(lambda: state["chat"], outputs=chatbox)

demo.launch(

)